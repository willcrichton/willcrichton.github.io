<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:creator" content="@tonofcrates" />  
  <meta property="og:title" content="Research Statement" />
  <title>Research Statement</title> 
  <style></style>
  <style>
/*
 * I add this to html files generated with pandoc.
 */

 html {
  font-size: 100%;
  overflow-y: scroll;
  -webkit-text-size-adjust: 100%;
  -ms-text-size-adjust: 100%;
}

body {
  color: black;
  font-family: Palatino, 'Palatino Linotype', Georgia, Times, 'Times New Roman', serif;
  font-size: 16px;
  line-height: 1.7;
  padding: 1em;
  margin: auto;
  max-width: 800px;
  background: white;
}

p {
  hyphens: auto;
  overflow-wrap: anywhere;
  word-spacing: -1px;
}

a {
  text-decoration-thickness: 1px;
}

/* 
a {
  color: #0645ad;
}

a:visited {
  color: #0b0080;
}

a:hover {
  color: #06e;
}

a:active {
  color: #faa700;
}

a:focus {
  outline: thin dotted;
} */

p {
  margin: 1em 0;
}

img {
  max-width: 100%;
}

h1, h2, h3, h4, h5, h6 {
  color: #111;
  line-height: 125%;
  margin-top: 2em;
  font-weight: normal;
}

h4, h5, h6 {
  font-weight: bold;
}

h1 {
  font-size: 2.25em;
}

h2 {
  font-size: 1.75em;
}

h3 {
  font-size: 1.3em;
}

h4 {
  font-size: 1.1em;
}

h5 {
  font-size: 1em;
}

h6 {
  font-size: 0.9em;
}

blockquote {
  color: #666666;
  margin: 0;
  padding-left: 1em;
  border-left: 0.5em #EEE solid;
}

hr {
  display: block;
  height: 2px;
  border: 0;
  border-top: 1px solid #aaa;
  border-bottom: 1px solid #eee;
  margin: 1em 0;
  padding: 0;
}

pre, code, kbd, samp {
  color: #000;
  font-family: Inconsolata, monospace;
  /* _font-family: 'courier new', monospace; */
  font-size: 0.98em;
}

/* pre {
  white-space: pre;
  white-space: pre-wrap;
  word-wrap: break-word;
} */

b, strong {
  font-weight: bold;
}

dfn {
  font-style: italic;
}

ins {
  background: #ff9;
  color: #000;
  text-decoration: none;
}

mark {
  background: #ff0;
  color: #000;
  font-style: italic;
  font-weight: bold;
}

sub, sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}

sup {
  top: -0.5em;
}

sub {
  bottom: -0.25em;
}

ul, ol {
  margin: 1em 0;
  padding: 0 0 0 2em;
}

li p:last-child {
  margin-bottom: 0;
}

ul ul, ol ol {
  margin: .3em 0;
}

dl {
  margin-bottom: 1em;
}

dt {
  font-weight: bold;
  margin-bottom: .8em;
}

dd {
  margin: 0 0 .8em 2em;
}

dd:last-child {
  margin-bottom: 0;
}

img {
  border: 0;
  -ms-interpolation-mode: bicubic;
  vertical-align: middle;
}

figure {
  display: block;
  text-align: center;
  margin-left: 0;
  margin-right: 0;
}

figure img {
  border: none;
  margin: 0 auto;
}

figcaption {  
  margin: 0 0 .8em;
}

table {
  margin-top: 2em;
  margin-bottom: 3em;
  border-bottom: 1px solid #ddd;
  border-right: 1px solid #ddd;
  border-spacing: 0;
  border-collapse: collapse;
}

table th {
  padding: .2em 1em;
  background-color: #eee;
  border-top: 1px solid #ddd;
  border-left: 1px solid #ddd;
}

table td {
  padding: .2em 1em;
  border-top: 1px solid #ddd;
  border-left: 1px solid #ddd;
  vertical-align: top;
}

.author {
  font-size: 1.2em;
  text-align: center;
  font-style: italic;
}

.date {
  margin-left: 2em;
}

#refs {
  margin-top: 4em;
}

@media only screen and (min-width: 480px) {
  body {
    font-size: 16px;
  }
}
@media only screen and (min-width: 768px) {
  body {
    font-size: 18px;
  }

  p {
    text-align: justify;
  }
}

@media only screen and (max-width: 768px) {
  h1 {
    margin-top: 0;
  }

  ul, ol {
    padding-left: 1em;
  }
}

@media only screen and (min-width: 1200px) {
  .hero {
    width: 1200px;
    max-width: none;
    position: relative;
    right: 200px;
  }

  figure {
    margin: 2em 3em;
  }
}
@media print {
  * {
    background: transparent !important;
    color: black !important;
    filter: none !important;
    -ms-filter: none !important;
  }

  body {
    font-size: 12pt;
    max-width: 100%;
  }

  a, a:visited {
    text-decoration: underline;
  }

  hr {
    height: 1px;
    border: 0;
    border-bottom: 1px solid black;
  }

  a[href]:after {
    content: " (" attr(href) ")";
  }

  abbr[title]:after {
    content: " (" attr(title) ")";
  }

  .ir a:after, a[href^="javascript:"]:after, a[href^="#"]:after {
    content: "";
  }

  pre, blockquote {
    border: 1px solid #999;
    padding-right: 1em;
    page-break-inside: avoid;
  }

  tr, img {
    page-break-inside: avoid;
  }

  img {
    max-width: 100% !important;
  }

  @page :left {
    margin: 15mm 20mm 15mm 10mm;
}

  @page :right {
    margin: 15mm 10mm 15mm 20mm;
}

  p, h2, h3 {
    orphans: 3;
    widows: 3;
  }

  h2, h3 {
    page-break-after: avoid;
  }
}

.hero {
  margin: 0.5em 0 2em;
}

div.sourceCode, pre {
  background: #fafafa;
  padding: 0.25em 0.5em;
  overflow-x: auto;
}

p code, li code {
  background: #f5f5f5;
  padding: 1px 2px;
}

figure, body > div {
  max-width: 100%;
  overflow-x: auto;
}

.center {
  display: block;
  margin: 0 auto;
}

  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Research Statement</h1>
</header>
<p><img src="research-teaser.jpg" alt="image" /> <span id="header"
label="header"></span></p>
<p>All people should be able to program, and all programmers should be
able to build complex software. However, computational literacy today is
like textual literacy in antiquity; just as reading was the exclusive
skill of the ancient privileged castes, so too is programming the
exclusive skill of <span class="math inline">1%</span> of today’s
population. The number of programmers who can build reliable software
systems or analyze massive datasets is vanishingly small. My mission is
to empower people to tackle programming problems at all levels of
complexity.</p>
<p>My approach is to build systems that <em>amplify the intelligence of
programmers</em>, in the sense used by computing pioneers like
Bush <span class="citation" data-cites="bush1945"><sup>[<a
href="#ref-bush1945" role="doc-biblioref">1</a>]</sup></span>,
Engelbart <span class="citation" data-cites="engelbart1962"><sup>[<a
href="#ref-engelbart1962" role="doc-biblioref">2</a>]</sup></span>, and
Licklider <span class="citation" data-cites="licklider1960"><sup>[<a
href="#ref-licklider1960" role="doc-biblioref">3</a>]</sup></span>. I
identify core cognitive tasks that are a challenging part of routine
programming, and I design systems to support people in accomplishing
those tasks. To both ground my ideas and maximize my impact, I work
within programmer communities that apply cutting-edge tools to design
complex software, with my current focus being on <a
href="https://rust-lang.org/">Rust</a>, a language for safe systems
programming. Specifically, I have developed tools to help Rust
programmers:</p>
<ul>
<li><p>Find relevant code by visualizing dependencies in the IDE <span
class="citation" data-cites="crichton2022flowistry"><sup>[<a
href="#ref-crichton2022flowistry"
role="doc-biblioref">4</a>]</sup></span> (top-right), used by 5,000+
Rust developers.</p></li>
<li><p>Learn Rust with novel conceptual models of its key features <span
class="citation" data-cites="crichton2023aquascope"><sup>[<a
href="#ref-crichton2023aquascope"
role="doc-biblioref">5</a>]</sup></span> (center), used by 60,000+ Rust
learners.</p></li>
<li><p>Learn APIs by linking documentation with examples <span
class="citation"
data-cites="crichton2021docgen crichton2021scrape"><sup>[<a
href="#ref-crichton2021docgen" role="doc-biblioref">6</a>,<a
href="#ref-crichton2021scrape" role="doc-biblioref">7</a>]</sup></span>,
merged into Rust and used by 100+ libraries.</p></li>
</ul>
<p>It is difficult to design effective systems for intelligence
amplification with intuition alone. People are hard to predict, and
programs are hard to analyze. In my research, I seek to build theories
as much as systems; to contribute to a shared foundation of knowledge
about how programs works (programming language theory) and how people
program (cognitive psychology). For example:</p>
<ul>
<li><p>I ran four experiments to understand how working memory
influences program comprehension <span class="citation"
data-cites="crichton2021wm"><sup>[<a href="#ref-crichton2021wm"
role="doc-biblioref">8</a>]</sup></span> (top-left), which motivated my
work on visualizing dependencies to overcome working memory
limitations.</p></li>
<li><p>I formalized my static dependency analysis for Rust
(bottom-right) and demonstrated its correctness by proving a key
theorem, termination-insensitive non-interference <span class="citation"
data-cites="crichton2022flowistry"><sup>[<a
href="#ref-crichton2022flowistry"
role="doc-biblioref">4</a>]</sup></span>.</p></li>
<li><p>I designed a formal semantics for document languages to provide a
precise theoretical foundation for my ongoing work in designing a
successor to LaTeX <span class="citation"
data-cites="crichton2024documents"><sup>[<a
href="#ref-crichton2024documents"
role="doc-biblioref">9</a>]</sup></span> (bottom-left).</p></li>
</ul>
<h2 class="unnumbered"
id="overcoming-working-memory-limitations-with-information-flow-analysis">Overcoming
Working Memory Limitations with Information Flow Analysis</h2>
<p>Intelligence amplification requires an understanding of programmer
cognition. So my thesis work started with the question: which
psychological theories can make concrete predictions about how people
perform programming tasks? After reviewing the literature on applied
cognitive psychology, I found a common theme: <em>working memory</em>,
or the cognitive capacity for processing information in the short-term.
The key finding is that working memory has a universally limited
capacity of 7-ish “chunks” of information. I asked: how would a
programmer’s working memory affect their ability to perform programming
tasks?</p>
<p>“The Role of Working Memory in Program Tracing” (CHI 2021,<span
class="citation" data-cites="crichton2021wm"><sup>[<a
href="#ref-crichton2021wm" role="doc-biblioref">8</a>]</sup></span>)
reports on four experiments examining the limits of human performance in
a straightforward programming task: <em>tracing</em>, or mentally
simulating a program’s behavior. When given a simple program like
“<code>x=8; y=2; z=4</code>” and then asked the value of <code>y</code>
(i.e., a paired-associate cued recall task), we found that most
participants started to make errors after about 7 variables, consistent
with working memory theory. More interestingly, we asked participants to
trace a program with an accumulating dependency structure like
“<code>x=8; y=x+2; z=y-1;</code> …”. We designed an interface to track a
participant’s attention by blurring-out code not under the participant’s
cursor. We found evidence for two distinct tracing strategies: reading
“linearly” top-down and reading “on-demand” in reverse dependency order.
These strategies corresponded to distinct working memory errors:
forgetting the value of a variable, and forgetting the location of a
prior computation. Overall, the experiments showed that a programmer’s
working memory severely limits their ability to mentally maintain
program state, and the nature of that state depends on the programmer’s
chosen strategy.</p>
<p>This result motivated the question: how can tools amplify a
programmer’s working memory to overcome these limitations? IDEs provide
some support with features like “Jump to Definition”, but they provide
no support for following the full dependency structure of a computation.
This task has historically been the domain of <em>program slicing</em> —
yet despite decades of work, no slicer is in widespread use today. So I
focused on developing a new program slicer with two criteria: (1) the
analysis is practical enough to run on large codebases, and (2) the
interface provides cognitive support for program comprehension
tasks.</p>
<p>“Modular Information Flow through Ownership” (PLDI 2022,<span
class="citation" data-cites="crichton2022flowistry"><sup>[<a
href="#ref-crichton2022flowistry"
role="doc-biblioref">4</a>]</sup></span>) describes a practical static
slicer for Rust, or more generally for computing <em>information
flow</em> in Rust (of which slicing is a special case). The key insight
is that both alias analysis and mutation analysis can be made
<em>modular</em> by careful use of the Rust type system. Our algorithm
can analyze flows through function calls only using ownership
annotations on the type signature, without needing the function body
itself. To evaluate soundness, we proved that this approximation
satisfies termination-insensitive non-interference within a formal model
of safe Rust. To evaluate precision, we analyzed <span
class="math inline"> ≈ 400, 000</span> lines of Rust code and found that
this approximation is equivalent to a whole-program analysis in 94% of
cases, meaning that little precision is lost. The modular information
flow algorithm is publicly available as the Flowistry tool  (<a
href="https://github.com/willcrichton/flowistry">willcrichton/flowistry</a>) .</p>
<p>Flowistry is supporting two ongoing research projects. First, I
developed an IDE tool that interactively visualizes Flowistry’s output
as program slices, which has been used by over 5,000 Rust developers to
date. I am running experiments to study how Flowistry influences a
developer’s process of comprehending code. Second, I am working with
colleagues at Brown to use Flowistry as the foundation for Paralegal 
(<a href="https://github.com/brownsys/paralegal">brownsys/paralegal</a>) , an IFC system
that can identify security violations in Rust codebases.</p>
<h2 class="unnumbered" id="teaching-ownership-types-at-scale">Teaching
Ownership Types at Scale</h2>
<p>Another key cognitive task for all programmers is <em>learning</em> —
a particular problem for Rust, whose combination of concepts from
functional and systems programming is notoriously difficult to master.
During my postdoc, I set out to systematically improve Rust’s learning
curve by developing an experimental platform for teaching Rust at scale.
The Rust Book Experiment  (<a
href="https://rust-book.cs.brown.edu/">rust-book.cs.brown.edu</a>) is a fork of <em>The Rust
Programming Language</em>, the Rust community’s official textbook. The
key idea is to embed interactive quizzes within the book. Learners
benefit because the quizzes help them engage with the material. We
benefit by collecting large quantities of data about which parts of Rust
are hardest to learn. Over the last year, 60,000+ people have answered
quiz questions over 1,000,000 times using our platform.</p>
<p>“A Grounded Conceptual Model for Ownership Types in Rust” (OOPSLA
2023,<span class="citation" data-cites="crichton2023aquascope"><sup>[<a
href="#ref-crichton2023aquascope"
role="doc-biblioref">5</a>]</sup></span>) describes one part of this
experiment focused on ownership. We first ran a formative study with
<span class="math inline">36</span> Rust learners who answered
open-ended problems about ownership. We found that learners could
recognize the surface reason for why a program is rejected (e.g., there
are two mutable references to the same data), but they could not
articulate the underlying reason (e.g,. with a particular input, the
code would have undefined behavior).</p>
<p>We developed a new pedagogy of ownership to address this disconnect.
At its heart is a conceptual model of ownership types as flow-sensitive
<em>permissions</em> to read, write, or own data. We built a compiler
plugin that takes a Rust program and generates a diagram showing how
each statement affects permissions. Finally, we wrote a replacement
chapter on ownership for the Rust Book that uses these diagrams (<a
href="https://rust-book.cs.brown.edu/ch04-02-references-and-borrowing.html">link</a>).</p>
<p>We evaluated the permissions pedagogy by comparing the learning
outcomes of our new text versus the baseline chapter on ownership in
<em>The Rust Programming Language</em>. To measure learning outcomes, we
designed and deployed an instrument to evaluate learners’ understanding
of ownership. An A/B test of the two texts found that our pedagogy
improved average scores on the instrument by +9% (<span
class="math inline"><em>N</em> = 312</span>, <span
class="math inline"><em>p</em> &lt; 0.001</span>, <span
class="math inline"><em>d</em> = 0.56</span>). More broadly, this
experiment validated our hypothesis that gathering quiz data at scale
would be a useful tool for designing and evaluating language learning
interventions.</p>
<h2 class="unnumbered" id="future-work">Future Work</h2>
<p>Below are several research questions that I am interested to work on
during my professorship.</p>
<h4 id="what-should-be-the-successor-to-tex">What should be the
successor to TeX?</h4>
<p>The modern document uses teraflops of processing power and millions
of pixels to… render stylized text on emulated <span
class="math inline">8.5” × 11”</span> pieces of paper. Absurd! That made
sense at the birth of TeX in 1978, but the future of communication needs
better document technologies. I want to study this problem from the
cognitive and PL perspectives. First, which aspects of reading
comprehension could be better facilitated by changes to the
communication medium? For instance, “explorable explanations” are
probably less cognitively useful compared to ideas such as: all symbols
should be linked back to their definition. All figures should be visible
on-screen when a person is reading text about a figure. All text should
come with machine-checkable comprehension questions to engage the
reader.</p>
<p>But this begs the PL perspective: how should we design a document
language to make the necessary cognitive augmentations practical for
authors, especially those without significant training in technical
communication, educational psychology, and visual design? How can
document languages make it easy to correctly compose content and
computation? My prototype language Nota  (<a
href="https://nota-lang.org/">nota-lang/nota</a>) and my document calculus
formalism (POPL 2024,<span class="citation"
data-cites="crichton2024documents"><sup>[<a
href="#ref-crichton2024documents"
role="doc-biblioref">9</a>]</sup></span>) are my first steps in this
direction.</p>
<h4
id="how-will-ai-programming-tools-change-the-nature-of-programming-expertise">How
will AI programming tools change the nature of programming
expertise?</h4>
<p>Tools like GitHub Copilot have made a splash in the programming
community. For programmers, the question is: how should they most
effectively incorporate these tools into their workflow? For programming
language designers: how should they design language syntax and semantics
when knowing that future code is equally likely to be written by a
machine as much a person? Psychology provides the useful framework of
<em>recognition vs. recall</em>. Programming has long been a
recall-oriented activity — programmers commit to memory the syntax and
semantics of a language, and write programs by recalling that knowledge.
AI shifts towards recognition — programmers ask for a program, and
recognize whether the generated code is satisfactory. I want to study
the cognition of program recognition: how the features of a program and
the aspects of a person’s background would help or hamper them in
distinguishing desirable from undesirable programs.</p>
<h4
id="what-are-useful-lightweight-metrics-for-comparing-the-expressiveness-of-software-systems">What
are useful, lightweight metrics for comparing the expressiveness of
software systems?</h4>
<p>Library developers love to market their software as being “easy to
use” or “for humans”. Researchers often claim that their systems are
often “more expressive” than prior work. However, the singular metric
that often justifies these claims is lines-of-code. Despite the metric’s
imperfection, no one has yet come up with an alternative besides “run a
large-scale user study” or “deploy the tool in industry and see who
adopts it.” Here’s a hypothesis I want to test: the length of the
argument for why a program is correct (say, the size of a proof in a
proof assistant) has a higher correlation with program comprehension
effort than the length of the program itself. If this hypothesis could
be experimentally validated, then that would be grounds for developing a
new expressiveness metric. A system that lends itself to short proofs
across a benchmark of reference tasks could be predicted as more usable
(to an expert) than a system requiring longer proofs.</p>
<div id="refs" class="references csl-bib-body hanging-indent"
data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-bush1945" class="csl-entry" role="listitem">
1. Bush, V. (1945). As we may think. <em>The Atlantic</em>,
<em>176</em>(1), 101–108.
</div>
<div id="ref-engelbart1962" class="csl-entry" role="listitem">
2. Engelbart, D. (1962). <em>Augmenting human intellect: A conceptual
framework</em>. Stanford Research Institute.
</div>
<div id="ref-licklider1960" class="csl-entry" role="listitem">
3. Licklider, J. C. R. (1960). Man-computer symbiosis. <em>IRE
Transactions on Human Factors in Electronics</em>, <em>HFE-1</em>(1),
4–11. <a
href="https://doi.org/10.1109/THFE2.1960.4503259">https://doi.org/10.1109/THFE2.1960.4503259</a>
</div>
<div id="ref-crichton2022flowistry" class="csl-entry" role="listitem">
4. Crichton, W., Patrignani, M., Agrawala, M., &amp; Hanrahan, P.
(2022). Modular information flow through ownership. <em>Proceedings of
the 43rd ACM SIGPLAN International Conference on Programming Language
Design and Implementation</em>, 1–14. <a
href="https://doi.org/10.1145/3519939.3523445">https://doi.org/10.1145/3519939.3523445</a>
</div>
<div id="ref-crichton2023aquascope" class="csl-entry" role="listitem">
5. Crichton, W., Gray, G., &amp; Krishnamurthi, S. (2023). A grounded
conceptual model for ownership types in rust. <em>Proc. ACM Program.
Lang.</em>, <em>OOPSLA2</em>.
</div>
<div id="ref-crichton2021docgen" class="csl-entry" role="listitem">
6. Crichton, W. (2021). Documentation generation as information
visualization. <em>Proceedings of the 11th Annual Workshop on the
Intersection of HCI and PL</em>. <a
href="http://reports-archive.adm.cs.cmu.edu/anon/isr2020/abstracts/20-115E.html">http://reports-archive.adm.cs.cmu.edu/anon/isr2020/abstracts/20-115E.html</a>
</div>
<div id="ref-crichton2021scrape" class="csl-entry" role="listitem">
7. Crichton, W. (2021). <em>RFC #3122: Automatically scrape code
examples for rustdoc</em>. <a
href="https://github.com/rust-lang/rfcs/blob/master/text/3123-rustdoc-scrape-examples.md">https://github.com/rust-lang/rfcs/blob/master/text/3123-rustdoc-scrape-examples.md</a>
</div>
<div id="ref-crichton2021wm" class="csl-entry" role="listitem">
8. Crichton, W., Agrawala, M., &amp; Hanrahan, P. (2021). The role of
working memory in program tracing. <em>Proceedings of the 2021 CHI
Conference on Human Factors in Computing Systems</em>. <a
href="https://doi.org/10.1145/3411764.3445257">https://doi.org/10.1145/3411764.3445257</a>
</div>
<div id="ref-crichton2024documents" class="csl-entry" role="listitem">
9. Crichton, W., &amp; Krishnamurthi, S. (2024). A core calculus for
documents. <em>Proc. ACM Program. Lang.</em>, <em>POPL</em>.
</div>
</div>
</body>
</html>